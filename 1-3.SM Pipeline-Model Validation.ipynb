{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b63e57-b89e-453d-ae13-c4ed75c5bf1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_MODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b92b83-c7aa-49b1-a1ed-a976c863c1a9",
   "metadata": {},
   "source": [
    "# 0. 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81535be4-39fc-4dd8-a95c-9d83f6fdd9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import subprocess, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "import logging\n",
    "import logging.handlers\n",
    "\n",
    "import json\n",
    "import base64\n",
    "import boto3\n",
    "import sagemaker\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "from dateutil.relativedelta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79a1a68-de80-4877-a7ec-76b7b5823aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret():\n",
    "    secret_name = \"dev/ForecastPalmOilPrice\"\n",
    "    region_name = \"ap-northeast-2\"\n",
    "    \n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException': # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException': # An error occurred on the server side.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException': # You provided an invalid value for a parameter.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException': # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException': # We can't find the resource that you asked for.\n",
    "            raise e\n",
    "    else:\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            secret = get_secret_value_response['SecretString']\n",
    "            return secret\n",
    "        else:\n",
    "            decoded_binary_secret = base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "            return decoded_binary_secret\n",
    "\n",
    "keychain = json.loads(get_secret())\n",
    "ACCESS_KEY_ID = keychain['AWS_ACCESS_KEY_ID']\n",
    "ACCESS_SECRET_KEY = keychain['AWS_ACCESS_SECRET_KEY']\n",
    "\n",
    "BUCKET_NAME_USECASE = keychain['PROJECT_BUCKET_NAME']\n",
    "DATALAKE_BUCKET_NAME = keychain['DATALAKE_BUCKET_NAME']\n",
    "\n",
    "S3_PATH_REUTER = keychain['S3_PATH_REUTER']\n",
    "S3_PATH_WWO = keychain['S3_PATH_WWO']\n",
    "S3_PATH_STAGE = keychain['S3_PATH_STAGE']\n",
    "S3_PATH_GOLDEN = keychain['S3_PATH_GOLDEN']\n",
    "S3_PATH_TRAIN = keychain['S3_PATH_TRAIN']\n",
    "S3_PATH_FORECAST = keychain['S3_PATH_PREDICTION']\n",
    "\n",
    "region = 'ap-northeast-2'\n",
    "boto3_session = boto3.Session(aws_access_key_id = ACCESS_KEY_ID,\n",
    "                              aws_secret_access_key = ACCESS_SECRET_KEY,\n",
    "                              region_name = region)\n",
    "sm_session = sagemaker.Session(boto_session = boto3_session)\n",
    "\n",
    "s3_resource = boto3_session.resource('s3')\n",
    "palmoil_bucket = s3_resource.Bucket(BUCKET_NAME_USECASE)\n",
    "datalake_bucket = s3_resource.Bucket(DATALAKE_BUCKET_NAME)\n",
    "\n",
    "sm_client = boto3_session.client('sagemaker')\n",
    "qs_client = boto3_session.client('quicksight')\n",
    "s3_client = boto3_session.client('s3')\n",
    "sts_client = boto3_session.client(\"sts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f4a081-5216-488d-89e4-994dab68146d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/v1.2/model_validation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/v1.2/model_validation.py\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import argparse\n",
    "import json\n",
    "import boto3\n",
    "from io import StringIO, BytesIO\n",
    "import joblib\n",
    "import sys\n",
    "import subprocess\n",
    "import logging\n",
    "import logging.handlers\n",
    "import calendar\n",
    "import tarfile\n",
    "\n",
    "\n",
    "###############################\n",
    "######### util 함수 설정 ##########\n",
    "###############################\n",
    "def _get_logger():\n",
    "    loglevel = logging.DEBUG\n",
    "    l = logging.getLogger(__name__)\n",
    "    if not l.hasHandlers():\n",
    "        l.setLevel(loglevel)\n",
    "        logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))        \n",
    "        l.handler_set = True\n",
    "    return l  \n",
    "logger = _get_logger()\n",
    "\n",
    "def get_secret():\n",
    "    secret_name = \"dev/ForecastPalmOilPrice\"\n",
    "    region_name = \"ap-northeast-2\"\n",
    "    \n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException': # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException': # An error occurred on the server side.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException': # You provided an invalid value for a parameter.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException': # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException': # We can't find the resource that you asked for.\n",
    "            raise e\n",
    "    else:\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            secret = get_secret_value_response['SecretString']\n",
    "            return secret\n",
    "        else:\n",
    "            decoded_binary_secret = base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "            return decoded_binary_secret\n",
    "\n",
    "def check_performance_threshold(iput_df : pd.DataFrame,\n",
    "                                identifier: str,\n",
    "                                threshold : float = -100):\n",
    "    tmp = {}\n",
    "    satisfied_df = iput_df[iput_df['score_val'] > threshold]\n",
    "    if len(satisfied_df) > 0:\n",
    "        tmp['identifier'] = identifier\n",
    "        tmp['model'] = list(satisfied_df['model'])\n",
    "        tmp['performance'] = list(satisfied_df['score_val'])\n",
    "    return tmp\n",
    "\n",
    "def get_model_performance_report(data):\n",
    "    result = defaultdict(list)\n",
    "    models_ext = [row[\"model\"] for row in data if row]\n",
    "    models = [item for sublist in models_ext for item in sublist]\n",
    "    performance_ext = [row[\"performance\"] for row in data if row]\n",
    "    performance = [item for sublist in performance_ext for item in sublist]\n",
    "    \n",
    "    count_models = Counter(models)\n",
    "    \n",
    "    for keys, values in zip(models, performance):\n",
    "        result[keys].append(values)\n",
    "\n",
    "    for key, values in result.items():\n",
    "        result[key] = []\n",
    "        result[key].append(count_models[key])\n",
    "        result[key].append(sum(values) / len(values))\n",
    "        result[key].append(np.std(values))\n",
    "    \n",
    "    # 정렬 1순위 : 비즈니스담당자의 Metric에 선정된 Count 높은 순, 2순위: 표준편차가 작은 순(그래서 -처리해줌)\n",
    "    result = sorted(result.items(), key=lambda k_v: (k_v[1][0], -k_v[1][2]), reverse=True) \n",
    "    return result\n",
    "\n",
    "def register_model_in_aws_registry(model_zip_path: str,\n",
    "                                   model_package_group_name: str,\n",
    "                                   model_description: str,\n",
    "                                   model_status: str,\n",
    "                                   sm_client) -> str:\n",
    "    create_model_package_input_dict = {\n",
    "        \"ModelPackageGroupName\": model_package_group_name,\n",
    "        \"ModelPackageDescription\": model_description,\n",
    "        \"ModelApprovalStatus\": model_status,\n",
    "        \"InferenceSpecification\": {\n",
    "            \"Containers\": [\n",
    "                {\n",
    "                    \"Image\": '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/autogluon-inference:0.4-cpu-py38',\n",
    "                    \"ModelDataUrl\": model_zip_path\n",
    "                }\n",
    "            ],\n",
    "            \"SupportedContentTypes\": [\"text/csv\"],\n",
    "            \"SupportedResponseMIMETypes\": [\"text/csv\"],\n",
    "        }\n",
    "    }\n",
    "    create_model_package_response = sm_client.create_model_package(**create_model_package_input_dict)\n",
    "    model_package_arn = create_model_package_response[\"ModelPackageArn\"]\n",
    "    return model_package_arn\n",
    "\n",
    "\n",
    "def register_manifest(source_path,\n",
    "                      target_path,\n",
    "                      s3_client,\n",
    "                      BUCKET_NAME_USECASE):\n",
    "    template_json = {\"fileLocations\": [{\"URIPrefixes\": []}],\n",
    "                     \"globalUploadSettings\": {\n",
    "                         \"format\": \"CSV\",\n",
    "                         \"delimiter\": \",\"\n",
    "                     }}\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    response_iterator = paginator.paginate(Bucket = BUCKET_NAME_USECASE,\n",
    "                                           Prefix = source_path.split(BUCKET_NAME_USECASE+'/')[1]\n",
    "                                          )\n",
    "    for page in response_iterator:\n",
    "        for content in page['Contents']:\n",
    "            template_json['fileLocations'][0]['URIPrefixes'].append(f's3://{BUCKET_NAME_USECASE}/'+content['Key'])\n",
    "    with open(f'./manifest_testing.manifest', 'w') as f:\n",
    "        json.dump(template_json, f, indent=2)\n",
    "\n",
    "    res = s3_client.upload_file('./manifest_testing.manifest',\n",
    "                                BUCKET_NAME_USECASE,\n",
    "                                f\"{target_path.split(BUCKET_NAME_USECASE+'/')[1]}/visual_validation.manifest\")\n",
    "    return f\"{target_path.split(BUCKET_NAME_USECASE+'/')[1]}/visual_validation.manifest\"\n",
    "    \n",
    "def refresh_of_spice_datasets(user_account_id,\n",
    "                              qs_data_name,\n",
    "                              manifest_file_path,\n",
    "                              BUCKET_NAME_USECASE,\n",
    "                              qs_client):\n",
    "    \n",
    "    ds_list = qs_client.list_data_sources(AwsAccountId='108594546720')\n",
    "    datasource_ids = [summary[\"DataSourceId\"] for summary in ds_list[\"DataSources\"] if qs_data_name in summary[\"Name\"]]    \n",
    "    for datasource_id in datasource_ids:\n",
    "        response = qs_client.update_data_source(\n",
    "            AwsAccountId=user_account_id,\n",
    "            DataSourceId=datasource_id,\n",
    "            Name=qs_data_name,\n",
    "            DataSourceParameters={\n",
    "                'S3Parameters': {\n",
    "                    'ManifestFileLocation': {\n",
    "                        'Bucket': BUCKET_NAME_USECASE,\n",
    "                        'Key':  f\"{manifest_file_path.split(BUCKET_NAME_USECASE+'/')[1]}/visual_validation.manifest\"\n",
    "                    },\n",
    "                },\n",
    "            })\n",
    "        logger.info(f\"datasource_id:{datasource_id} 의 manifest를 업데이트: {response}\")\n",
    "    \n",
    "    res = qs_client.list_data_sets(AwsAccountId = user_account_id)\n",
    "    datasets_ids = [summary[\"DataSetId\"] for summary in res[\"DataSetSummaries\"] if qs_data_name in summary[\"Name\"]]\n",
    "    ingestion_ids = []\n",
    "\n",
    "    for dataset_id in datasets_ids:\n",
    "        try:\n",
    "            ingestion_id = str(calendar.timegm(time.gmtime()))\n",
    "            qs_client.create_ingestion(DataSetId = dataset_id,\n",
    "                                       IngestionId = ingestion_id,\n",
    "                                       AwsAccountId = user_account_id)\n",
    "            ingestion_ids.append(ingestion_id)\n",
    "        except Exception as e:\n",
    "            logger.info(e)\n",
    "            pass\n",
    "    for ingestion_id, dataset_id in zip(ingestion_ids, datasets_ids):\n",
    "        while True:\n",
    "            response = qs_client.describe_ingestion(DataSetId = dataset_id,\n",
    "                                                    IngestionId = ingestion_id,\n",
    "                                                    AwsAccountId = user_account_id)\n",
    "            if response['Ingestion']['IngestionStatus'] in ('INITIALIZED', 'QUEUED', 'RUNNING'):\n",
    "                time.sleep(5)     #change sleep time according to your dataset size\n",
    "            elif response['Ingestion']['IngestionStatus'] == 'COMPLETED':\n",
    "                print(\"refresh completed. RowsIngested {0}, RowsDropped {1}, IngestionTimeInSeconds {2}, IngestionSizeInBytes {3}\".format(\n",
    "                    response['Ingestion']['RowInfo']['RowsIngested'],\n",
    "                    response['Ingestion']['RowInfo']['RowsDropped'],\n",
    "                    response['Ingestion']['IngestionTimeInSeconds'],\n",
    "                    response['Ingestion']['IngestionSizeInBytes']))\n",
    "                break\n",
    "            else:\n",
    "                logger.info(\"refresh failed for {0}! - status {1}\".format(dataset_id,\n",
    "                                                                          response['Ingestion']['IngestionStatus']))\n",
    "                break\n",
    "    return response\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--leaderboard_path', type=str, default=\"/opt/ml/processing/input/leaderboard\")   \n",
    "    parser.add_argument('--model_base_path', type=str)\n",
    "    parser.add_argument('--manifest_base_path', type=str)\n",
    "    parser.add_argument('--prediction_base_path', type=str)\n",
    "    parser.add_argument('--threshold', type=str, default=\"-100\")   \n",
    "    parser.add_argument('--model_package_group_name', type=str, default = BUCKET_NAME_USECASE)  \n",
    "    parser.add_argument('--qs_data_name', type=str, default = 'model_result')    \n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    logger.info(f\"\\n### Loading Key value from Secret Manager\")\n",
    "    keychain = json.loads(get_secret())\n",
    "    ACCESS_KEY_ID = keychain['AWS_ACCESS_KEY_ID']\n",
    "    ACCESS_SECRET_KEY = keychain['AWS_ACCESS_SECRET_KEY']\n",
    "    BUCKET_NAME_USECASE = keychain['PROJECT_BUCKET_NAME']\n",
    "    DATALAKE_BUCKET_NAME = keychain['DATALAKE_BUCKET_NAME']\n",
    "    S3_PATH_REUTER = keychain['S3_PATH_REUTER']\n",
    "    S3_PATH_WWO = keychain['S3_PATH_WWO']\n",
    "    S3_PATH_STAGE = keychain['S3_PATH_STAGE']\n",
    "    S3_PATH_GOLDEN = keychain['S3_PATH_GOLDEN']\n",
    "    S3_PATH_TRAIN = keychain['S3_PATH_TRAIN']\n",
    "    S3_PATH_FORECAST = keychain['S3_PATH_PREDICTION']\n",
    "    \n",
    "    boto3_session = boto3.Session(aws_access_key_id = ACCESS_KEY_ID,\n",
    "                                  aws_secret_access_key = ACCESS_SECRET_KEY,\n",
    "                                  region_name = 'ap-northeast-2')\n",
    "    \n",
    "    s3_client = boto3_session.client('s3')\n",
    "    sm_client = boto3_session.client('sagemaker')\n",
    "    qs_client = boto3_session.client('quicksight')\n",
    "\n",
    "    sts_client = boto3_session.client(\"sts\")\n",
    "    user_account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "    ######################################\n",
    "    ## 커맨드 인자, Hyperparameters 처리 ##\n",
    "    ######################################\n",
    "    args = parse_args()\n",
    "    logger.info(\"######### Argument Info ####################################\")\n",
    "    logger.info(\"### start training code\")    \n",
    "    logger.info(\"### Argument Info ###\")\n",
    "    logger.info(f\"args.leaderboard_path: {args.leaderboard_path}\")    \n",
    "    logger.info(f\"args.model_base_path: {args.model_base_path}\")\n",
    "    logger.info(f\"args.manifest_base_path: {args.manifest_base_path}\")\n",
    "    logger.info(f\"args.prediction_base_path: {args.prediction_base_path}\")\n",
    "    logger.info(f\"args.threshold: {args.threshold}\")\n",
    "    logger.info(f\"args.model_package_group_name: {args.model_package_group_name}\")\n",
    "    logger.info(f\"args.qs_data_name: {args.qs_data_name}\")\n",
    "  \n",
    "    leaderboard_path = args.leaderboard_path\n",
    "    model_base_path = args.model_base_path\n",
    "    manifest_base_path = args.manifest_base_path\n",
    "    prediction_base_path = args.prediction_base_path\n",
    "    threshold = float(args.threshold)\n",
    "    model_package_group_name = args.model_package_group_name\n",
    "    qs_data_name = args.qs_data_name\n",
    "    \n",
    "    lb_list = sorted(os.listdir(leaderboard_path))\n",
    "    logger.info(f\"leaderboard file list in {leaderboard_path}: {lb_list}\")\n",
    "    satisfied_info = []\n",
    "    \n",
    "    for idx, f_path in enumerate(lb_list):\n",
    "        leaderboard = pd.read_csv(f'{leaderboard_path}/{f_path}').sort_values(by = ['score_val', 'score_test'],\n",
    "                                                                              ascending = False)\n",
    "        satisfied_info.append(check_performance_threshold(iput_df = leaderboard,\n",
    "                                                          identifier = f'fold{idx}',\n",
    "                                                          threshold = threshold))\n",
    "    model_report = get_model_performance_report(satisfied_info)\n",
    "\n",
    "    if model_report[0][1][0] == len(lb_list): # Fold 내 모든 성능이 비즈니스 담당자가 설정한 값을 만족한다면\n",
    "        logger.info(f\"\\n#### Pass the 1st minimum performance valiation\")\n",
    "        manifest_file_path = register_manifest(prediction_base_path, \n",
    "                                               manifest_base_path,\n",
    "                                               s3_client,\n",
    "                                     BUCKET_NAME_USECASE)\n",
    "        model_package_arn = register_model_in_aws_registry(f\"{model_base_path}/model.tar.gz\",\n",
    "                                                           model_package_group_name,\n",
    "                                                           ','.join(map(str,  model_report[0])),\n",
    "                                                           'PendingManualApproval',\n",
    "                                                           sm_client)\n",
    "        logger.info('### Passed ModelPackage Version ARN : {}'.format(model_package_arn))\n",
    "        res = refresh_of_spice_datasets(user_account_id,\n",
    "                                        qs_data_name,\n",
    "                                        manifest_file_path,\n",
    "                                        BUCKET_NAME_USECASE,\n",
    "                                        qs_client)\n",
    "        logger.info('### refresh_of_spice_datasets : {}'.format(res))\n",
    "    else:\n",
    "        logger.info(f\"\\n#### Filtered at 1st valiation\")\n",
    "        model_package_arn = register_model_in_aws_registry(f\"{model_base_path}/model.tar.gz\",\n",
    "                                                           model_package_group_name,\n",
    "                                                           ','.join(map(str,  model_report[0])),\n",
    "                                                           'Rejected',\n",
    "                                                           sm_client)\n",
    "        logger.info('### Rejected ModelPackage Version ARN : {}'.format(model_package_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16f2ecca-d73f-4fd6-b46f-cf60e4d89b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: src/v1.2/model_validation.py to s3://crude-palm-oil-prices-forecast/src/model_validation.py\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp 'src/v1.2/model_validation.py' 's3://crude-palm-oil-prices-forecast/src/model_validation.py' --exclude \".ipynb_checkpoints*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fc72fec-e727-4634-abae-3eeea38c75d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_validation_code' (str)\n"
     ]
    }
   ],
   "source": [
    "model_validation_code = 's3://crude-palm-oil-prices-forecast/src/model_validation.py'\n",
    "%store model_validation_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c8f9d3-d976-4f6d-a685-9ade98b54ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "model_validation_code             -> 's3://crude-palm-oil-prices-forecast/src/model_val\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224de32f-be04-4de9-96c0-28dcf74849d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48076217-25da-4928-95d6-7b901c548edc",
   "metadata": {},
   "source": [
    "# 1. 모델 검증 파이프라인 의 스텝(Step) 생성\n",
    "## 1) 모델 검증 파이프라인 변수 생성\n",
    "파이프라인에서 사용할 파이프라인 파라미터를 정의합니다. 파이프라인을 스케줄하고 실행할 때 파라미터를 이용하여 실행조건을 커스마이징할 수 있습니다. 파라미터를 이용하면 파이프라인 실행시마다 매번 파이프라인 정의를 수정하지 않아도 됩니다.\n",
    "\n",
    "지원되는 파라미터 타입은 다음과 같습니다:\n",
    "\n",
    "- ParameterString - 파이썬 타입에서 str\n",
    "- ParameterInteger - 파이썬 타입에서 int\n",
    "- ParameterFloat - 파이썬 타입에서 float\n",
    "이들 파라미터를 정의할 때 디폴트 값을 지정할 수 있으며 파이프라인 실행시 재지정할 수도 있습니다. 지정하는 디폴트 값은 파라미터 타입과 일치하여야 합니다.\n",
    "\n",
    "본 노트북에서 사용하는 파라미터는 다음과 같습니다.\n",
    "\n",
    "- processing_instance_type - 프로세싱 작업에서 사용할 ml.* 인스턴스 타입\n",
    "- processing_instance_count - 프로세싱 작업에서 사용할 인스턴스 개수\n",
    "- validation_instance_type - 학습작업에서 사용할 ml.* 인스턴스 타입\n",
    "- model_approval_status - 학습된 모델을 CI/CD를 목적으로 등록할 때의 승인 상태 (디폴트는 \"PendingManualApproval\")\n",
    "- input_data - 입력데이터에 대한 S3 버킷 URI\n",
    "파이프라인의 각 스텝에서 사용할 변수를 파라미터 변수로서 정의 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f653b941-926b-4f60-9422-42450f1dbda7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "model_validation_instance_count = ParameterInteger(\n",
    "    name=\"ModelValidationInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "model_validation_instance_type = ParameterString(\n",
    "    name=\"ModelValidationInstanceType\",\n",
    "    default_value='ml.c5.xlarge'\n",
    ")\n",
    "input_leaderboard_data = ParameterString(\n",
    "    name=\"InputLeaderboardPath\",\n",
    "    default_value = 's3://crude-palm-oil-prices-forecast/trained-model/2023/02/26/1677484312.0/leaderboard',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d82ec-9aa5-47b7-bac4-81fa00e04b79",
   "metadata": {},
   "source": [
    "## 2) 로컬에서 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3a27bf-ec1b-450b-b16a-9d673acde734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOCAL_MODE:\n",
    "    # 도커 컨테이너 입력 폴더: staged data가 들어가는 부분\n",
    "    base_input_dir = 'opt/ml/processing/input'\n",
    "    os.makedirs(base_input_dir, exist_ok=True)\n",
    "    \n",
    "    # 도커 컨테이너 모델 폴더: model 데이터가 압축해제되고 실행되는곳\n",
    "    base_model_dir = 'opt/ml/model' \n",
    "    os.makedirs(base_model_dir, exist_ok=True)\n",
    "\n",
    "    # 도커 컨테이너 모델 폴더: prediction 데이터가 압축해제되고 실행되는곳\n",
    "    base_input_prediction_dir = 'opt/ml/processing/prediction'\n",
    "    os.makedirs(base_input_prediction_dir, exist_ok=True)\n",
    "        \n",
    "    # 도커 컨테이너 기본 출력 폴더\n",
    "    base_output_dir = 'opt/ml/processing/output'\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "    # 도커 컨테이너 출력 폴더: stage 데이터셋이 들어가는 부분\n",
    "    base_output_manifest_dir = f'{base_output_dir}/manifest'\n",
    "    os.makedirs(base_output_manifest_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd7f192-9a68-4c08-829b-e3f3be34d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python src/v1.2/model_validation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab3e03-992c-4cf8-82a6-c4ed92362660",
   "metadata": {},
   "source": [
    "## 3) 모델 검증 프로세서 정의\n",
    "전처리의 내장 SKLearnProcessor 를 통해서 sklearn_processor 오브젝트를 생성 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d645c9-fe96-499e-b83e-fdc1f2900195",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version = framework_version,\n",
    "    instance_type = model_validation_instance_type,\n",
    "    instance_count = model_validation_instance_count,\n",
    "    base_job_name = f\"{BUCKET_NAME_USECASE}(Validation Model)\",\n",
    "    role = sagemaker.get_execution_role(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7237f6e8-990e-4a31-a107-eeec3c39164a",
   "metadata": {},
   "source": [
    "## 4) 모델 검증 단계 정의\n",
    "처리 단계에서는 아래와 같은 주요 인자가 있습니다.\n",
    "단계 이름\n",
    "- processor 기술: 위에서 생성한 processor 오브젝트를 제공\n",
    "- inputs: S3의 경로를 기술하고, 다커안에서의 다운로드 폴더(destination)을 기술 합니다.\n",
    "- outputs: 처리 결과가 저장될 다커안에서의 폴더 경로를 기술합니다.\n",
    "\n",
    "도커안의 결과 파일이 저장 후에 자동으로 S3로 업로딩을 합니다.\n",
    "- job_arguments: 사용자 정의의 인자를 기술 합니다.\n",
    "- code: 전처리 코드의 경로를 기술 합니다.\n",
    "처리 단계의 상세한 사항은 여기를 보세요. --> 처리 단계, Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4f81331-a5ec-46ad-ada8-c52f2487a762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_base_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProcessingInput, ProcessingOutput\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msteps\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProcessingStep\n\u001b[1;32m      4\u001b[0m step_model_validaion \u001b[38;5;241m=\u001b[39m ProcessingStep(\n\u001b[1;32m      5\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBUCKET_NAME_USECASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-Validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     processor \u001b[38;5;241m=\u001b[39m sklearn_processor,\n\u001b[1;32m      7\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      8\u001b[0m             ProcessingInput(\n\u001b[1;32m      9\u001b[0m                 source \u001b[38;5;241m=\u001b[39m input_leaderboard_data,\n\u001b[1;32m     10\u001b[0m                 destination \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/opt/ml/processing/input/leaderboard\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     11\u001b[0m         ],\n\u001b[0;32m---> 12\u001b[0m     job_arguments\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--model_base_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmodel_base_path\u001b[49m,\n\u001b[1;32m     13\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--manifest_base_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, manifest_base_path,\n\u001b[1;32m     14\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--prediction_base_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction_base_path,\n\u001b[1;32m     15\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-100\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--model_package_group_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, BUCKET_NAME_USECASE,\n\u001b[1;32m     17\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--qs_data_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_result\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m                   ],\n\u001b[1;32m     19\u001b[0m     code \u001b[38;5;241m=\u001b[39m model_validation_code\n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_base_path' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "step_model_validaion = ProcessingStep(\n",
    "    name = f\"{BUCKET_NAME_USECASE}-Validation\",\n",
    "    processor = sklearn_processor,\n",
    "    inputs=[\n",
    "            ProcessingInput(\n",
    "                source = input_leaderboard_data,\n",
    "                destination = \"/opt/ml/processing/input/leaderboard\"),\n",
    "        ],\n",
    "    job_arguments=[\"--model_base_path\", model_base_path,\n",
    "                   \"--manifest_base_path\", manifest_base_path,\n",
    "                   \"--prediction_base_path\", 's3://crude-palm-oil-prices-forecast/trained-model/2023/02/26/1677484312.0/prediction',\n",
    "                   \"--threshold\", \"-100\",\n",
    "                   \"--model_package_group_name\", BUCKET_NAME_USECASE,\n",
    "                   \"--qs_data_name\", \"model_result\",\n",
    "                  ],\n",
    "    code = model_validation_code\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d68ee-062d-47c5-8fef-7456a43c7a35",
   "metadata": {},
   "source": [
    "## 5) 파리마터, 단계, 조건을 조합하여 최종 파이프라인 정의 및 실행\n",
    "이제 지금까지 생성한 단계들을 하나의 파이프라인으로 조합하고 실행하도록 하겠습니다.\n",
    "\n",
    "파이프라인은 name, parameters, steps 속성이 필수적으로 필요합니다. 여기서 파이프라인의 이름은 (account, region) 조합에 대하여 유일(unique))해야 합니다.\n",
    "\n",
    "주의:\n",
    "\n",
    "- 정의에 사용한 모든 파라미터가 존재해야 합니다.\n",
    "- 파이프라인으로 전달된 단계(step)들은 실행순서와는 무관합니다. SageMaker Pipeline은 단계가 실행되고 완료될 수 있도록 의존관계를를 해석합니다.\n",
    "- [알림] 정의한 stpes 이 복수개이면 복수개를 기술합니다. 만약에 step 간에 의존성이 있으면, 명시적으로 기술하지 않아도 같이 실행 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330ba1ed-7e76-4387-8f4f-529c01ea7577",
   "metadata": {},
   "source": [
    "### 5-1) 파이프라인 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd22d35-46ab-4a30-8387-af000fe44dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = project_prefix\n",
    "pipeline = Pipeline(name = pipeline_name,\n",
    "                    parameters = [\n",
    "                        model_validation_instance_type, \n",
    "                        model_validation_instance_count,\n",
    "                        input_leaderboard_data,\n",
    "                    ],\n",
    "                    steps = [step_model_validaion],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a93c78-c482-4244-b20b-4cd921d04037",
   "metadata": {},
   "source": [
    "### 5-2) 파이프라인 정의 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177fb252-7e0c-4f4b-9290-e1fc9e9594df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30dfd3f-bab2-48e2-9050-22609453370b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5-3) 파이프라인 정의를 제출하고 실행하기\n",
    "파이프라인 정의를 파이프라인 서비스에 제출합니다. 함께 전달되는 역할(role)을 이용하여 AWS에서 파이프라인을 생성하고 작업의 각 단계를 실행할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a6fdf-cb79-48fd-be67-3207b7eebbc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "pipeline.upsert(role_arn=sagemaker.get_execution_role())\n",
    "execution = pipeline.start()\n",
    "execution.wait() #실행이 완료될 때까지 기다린다.\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd52bf-60c8-48c6-9e20-9d6cd098ae03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"model validation 시간시간 : {((end - start)/60):.1f} min({end - start:.1f} sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01134f3-370f-4fac-9ee7-0adb63b76ced",
   "metadata": {},
   "source": [
    "- 2022년 11월 26일 Model validation : 4.5min\n",
    "- 2023년 03월 01일 Model validation : 4.6 min(273.5 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc85625-21a2-4d38-9ed8-fba8bf71475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f8c12-87f0-42f0-8dc3-431072192104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실행된 단계들을 리스트업. 파이프라인의 단계실행 서비스에 의해 시작되거나 완료된 단계를 보여준다.\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e865fb0-9557-4a77-89c2-750afcdb454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = execution.list_steps()\n",
    "proc_arn = response[-1]['Metadata']['ProcessingJob']['Arn'] # index -1은 가장 처음 실행 step\n",
    "proc_job_name = proc_arn.split('/')[-1] # Processing job name만 추출\n",
    "response = sm_client.describe_processing_job(ProcessingJobName = proc_job_name)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69da58f-0802-4922-b388-c3164485a1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
